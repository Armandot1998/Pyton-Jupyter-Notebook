{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overfittining.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPadQQLTx5MCG63ajFEBEP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armandot1998/Pyton-Jupyter-Notebook/blob/master/Overfittining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lnnw4ln1cyVj",
        "colab_type": "text"
      },
      "source": [
        "## Que es el Overfitting?\n",
        "\n",
        "El overfiting es cunado tu modelo se esta entrenando para resolver especificamente a los casos dados, es decir que el modelo generaliza el ruido de los datos.\n",
        "\n",
        "Dotar al modelo de una flexibilidad exagerada es por ede muy malo para el modelo, al presentarle al model un nuevo ambito que no conoce la taza de error de predecir será mayor.\n",
        "\n",
        "En Machine Learning, describimos el aprendizaje de la función objetivo a partir de los datos de entrenamiento como aprendizaje inductivo. Entendemos que la inducción se refiere al aprendizaje de conceptos generales a partir de ejemplos etiquetados específicos, que es exactamente el problema que los algoritmos de Machine Learning supervisado pretenden resolver. La capacidad de inducción de un modelo se refiere a cómo de preciso es un modelo de ML en entender ejemplos específicos que el mismo no vio cuando el algoritmo del que partía estaba siendo entrenado. El objetivo de un buen modelo de aprendizaje automático es generalizar bien los datos de entrenamiento a cualquier dato del dominio del problema. Esto nos permite hacer predicciones en el futuro sobre los datos que el modelo nunca ha visto.\n",
        "\n",
        "Las principales causas cuando se obtienen malos resultados al entrenar diferentes modelos de Machine Learning son el overfitting o el underfitting de los datos. Cuando entrenamos nuestro modelo intentamos ajustar los datos de entrada entre ellos y con la salida. En función de las características de nuestro dataset y de la elección de las muestras, se puede producir overfitting o “sobreajuste” y underfitting o “subajuste”. Estas dos casuísticas no dejan de ser más que la incapacidad de nuestro modelo de generalizar el dataset provisto.\n",
        "\n",
        "Es muy común que, al comenzar a entrenar el modelo, se caiga en el problema del underfitting. Lo que ocurrirá es que nuestro modelo sólo se ajustará a aprender los casos particulares que le enseñamos y será incapaz de reconocer nuevos datos de entrada. En nuestro conjunto de datos de entrada muchas veces introducimos muestras atípicas (o anómalas) o con ruido en alguna de sus dimensiones, o muestras que pueden no ser del todo representativas.\n",
        "\n",
        "Cuando sobre-entrenamos nuestro modelo y caemos en el overfitting, nuestro algoritmo estará considerando como válidos sólo los datos idénticos a los de nuestro conjunto de entrenamiento y siendo incapaz de distinguir entradas buenas como fiables si se salen un poco de los rangos ya preestablecidos. En la siguiente imagen vemos una simplificación a un ejemplo de regresión que nos permite visualizar el problema del underfitting y el overfitting. Encontrar un equilibrio para una correcta generalización se convierte en necesario.\n",
        "\n",
        "Para reconocer este problema deberemos subdividir nuestro conjunto de datos de entrada para entrenamiento en dos: uno para entrenamiento y otro para la validación que el modelo no conocerá de antemano. Esta división se suele hacer del 70-80% para entrenar y 20-30% para validar. El conjunto de validación deberá tener muestras lo más diversas posibles y en cuantía suficiente.\n",
        "\n",
        "- Error de entrenamiento: según se incrementa la complejidad del modelo, el modelo tiende a hacer un overfitting sobre los datos del entrenamiento. El error sobre los datos de entrenamiento irá decreciendo cada vez más.\n",
        "\n",
        "- Error de testeo: el error sobre el conjunto de validación es alto tanto en el escenario de underfitting como en el de overfitting. Nos interesa monitorizar este error para quedarnos justo en el punto de entrenamiento en el que este es menor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5-kg4IjeQV7",
        "colab_type": "text"
      },
      "source": [
        " - Condición de alto bias: nos encontramos con underfitting en nuestro modelo. Tanto el error de entrenamiento como el de testeo son elevados. Por más que añadamos datos para que el modelo explore, no se mejora el desempeño. Como solución se podría probar aumentar el número de características a analizar o la complejidad del algoritmo.\n",
        "\n",
        "- Condición de alta lvarianza: nuestro modeo está afectado por overfitting. Ajusta muy bien datos de entrenamiento, pero no es capaz de inferir correctamente los datos de validación, por lo que error de testeo es significativamente mayor que error de entrenamiento. Añadir datos variados ayuda a resolver el problema, así como la reducción de la complejidad del modelo.\n",
        "\n",
        "Si el modelo entrenado con el conjunto de test tiene un 90% de aciertos y con el conjunto de validación tiene un porcentaje muy bajo, nos enfrentamos ante un claro caso de overfitting. Si, por el contrario, en el conjunto de validación sólo se acierta un tipo de clase o el único resultado que se obtiene es siempre el mismo, nos encontramos ante un caso de underfitting.\n"
      ]
    }
  ]
}